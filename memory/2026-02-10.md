# 2026-02-10 - Daily Notes

## Sub-Agent Network Isolation Issue

### Problem Discovered
- **Issue**: Sub-agents spawned via `sessions_spawn` cannot access Brave Search MCP server
- **Root Cause**: Sandbox containers run with `network: none` for security isolation
- **Evidence**: `docker inspect openclaw-sbx-agent-main-subagent-*` shows `"Networks": { "none": {...} }`

### Diagnosis
- Main session can reach `brave-scraper-mcp:8080` via Docker network
- Sub-agent sandboxes have zero network access - can't resolve hostnames or reach any services
- This is by design in OpenClaw config: `"sandbox": { "mode": "non-main" }`

### Options Proposed to User
1. **Option A**: Update sandbox config to allow network access for sub-agents
2. **Option B**: Run research tasks in main session (works fine here)
3. **Option C**: Try workaround to let sub-agents reach host's exposed ports (0.0.0.0:8080)

### ✅ FIX APPLIED (Later in day)
- **Solution**: Option A chosen - updated sandbox config via `gateway config.patch`
- **Config change**: `agents.defaults.sandbox.docker.network` = `"traefik"`
- **Verification**: Spawned test sub-agent which successfully reached MCP server
  - Health check: `{"status":"healthy","server":"brave-scraper-mcp"}` ✅
  - Note: `mcporter` not installed in sandbox but network connectivity confirmed
- **Implication**: Sub-agents can now access all Docker services on traefik network

## Residential Proxy Research Task

- **Task**: Research best residential proxy servers for US web scraping
- **Sub-agent**: Spawned with label `proxy-research`
- **Result**: Completed successfully but used existing knowledge instead of live search
- **Output**: Report saved to `residential-proxy-research-2024-2025.md` in workspace
- **Top providers identified**: Bright Data, Oxylabs, Smartproxy, GeoSurf, PLA

## Brave Search MCP Skill Creation

### Task #37 Completed
- **Goal**: Create skill for Brave Search MCP server, deploy to project, push to GitHub, verify sub-agent usage
- **Skill location**: `/home/node/.openclaw/workspace/skills/brave-scraper-mcp/`
- **Also deployed to**: `brave-scraper-mcp/skills/brave-scraper-mcp/` in project repo
- **GitHub commit**: `9075278` - "Add agent skill for Brave Search MCP server"

### Key Finding: MCP Invocation Pattern
- **WRONG**: Calling tools directly as methods returns "Invalid request parameters"
  ```json
  {"method": "brave_search", "params": {"query": "test"}}  // ❌ FAILS
  ```
- **CORRECT**: Use `tools/call` with nested params
  ```json
  {"method": "tools/call", "params": {"name": "brave_search", "arguments": {"query": "test"}}}  // ✅ WORKS
  ```

### Sub-Agent Verification
- Spawned sub-agent successfully used MCP via raw curl
- Confirmed: `brave_search` for "OpenClaw AI assistant" returns correct results
- SKILL.md updated with correct MCP protocol pattern

### Skill Features
- Documents both `mcporter` CLI (main agent) and raw curl (sub-agent) usage
- Includes API reference with tool schemas
- ~~Notes that `mcporter` is NOT available in sandbox default image~~ **FIXED** (see Task #38)

## Task #38: mcporter in Sandbox Image

### Problem
- Sub-agents could only use MCP via raw curl (complex JSON-RPC)
- `mcporter` CLI was not installed in sandbox image
- Made MCP usage cumbersome for sub-agents

### Solution: Rebuild Sandbox Image
- **Image**: `openclaw-sandbox-common:bookworm-slim`
- **Installation**: `bun install -g mcporter` (v0.7.3)
- **Fix applied**: Created wrapper script because Node.js v18 in image doesn't support `/v` regex flag
  ```bash
  # Wrapper at /opt/bun/bin/mcporter
  exec bun /opt/bun/install/global/node_modules/mcporter/dist/cli.js "$@"
  ```

### Dockerfile
```dockerfile
FROM openclaw-sandbox-common:bookworm-slim
USER root
RUN id sandbox 2>/dev/null || useradd --create-home --shell /bin/bash sandbox
ENV BUN_INSTALL=/opt/bun
ENV PATH="${BUN_INSTALL}/bin:${PATH}"
RUN bun install -g mcporter
RUN mv /opt/bun/bin/mcporter /opt/bun/bin/mcporter-bin 2>/dev/null || true && \
    echo '#!/bin/bash' > /opt/bun/bin/mcporter && \
    echo 'exec bun /opt/bun/install/global/node_modules/mcporter/dist/cli.js "$@"' >> /opt/bun/bin/mcporter && \
    chmod +x /opt/bun/bin/mcporter
RUN mcporter --version
RUN chown -R sandbox:sandbox /home/sandbox
USER sandbox
WORKDIR /home/sandbox
CMD ["sleep", "infinity"]
```

### Verification
- Spawned sub-agent with label `mcporter-verification`
- Successfully ran: `mcporter call --allow-http http://brave-scraper-mcp:8080/mcp brave_search query="OpenClaw AI" count=3`
- Returned 3 search results ✅

### Impact
- Sub-agents can now use MCP tools natively with `mcporter` CLI
- Much simpler than raw curl JSON-RPC calls
- Network access already configured (traefik network)

## Brave MCP Server Bug (Discovered 2026-02-10)

### Issue: "No results found" despite results being extracted
- **Symptoms**: MCP returns "No results found" but logs show "Found N search results"
- **Root Cause**: `stateless=True` in StreamableHTTPSessionManager but single browser instance is reused
- **Evidence**: 
  - `docker logs brave-scraper-mcp` shows "Found 2 search results"
  - curl response: `{"content":[{"type":"text","text":"No results found"}]}`
- **Fix Options**:
  1. Create fresh browser context per request (slower but reliable)
  2. Add async locking to prevent concurrent navigation
  3. Restart browser between requests

### MCP Response Format (for reference)
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "content": [{"type": "text", "text": "Web Results for 'query':\n1. Title\n   URL: ...\n   Snippet..."}],
    "isError": false
  }
}
```

## Commands Reference
```bash
# Check sandbox network config
docker inspect openclaw-sbx-agent-main-subagent-* | grep -A 20 "NetworkSettings"

# Test MCP from main session
mcporter call brave-scraper.brave_search --args '{"query": "test", "count": 3}'

# Test MCP via raw curl (sub-agent compatible)
curl -N -s -X POST http://brave-scraper-mcp:8080/mcp/ \
  -H "Content-Type: application/json" \
  -H "Accept: application/json, text/event-stream" \
  -d '{"jsonrpc":"2.0","id":1,"method":"tools/call","params":{"name":"brave_search","arguments":{"query":"test","count":3}}}'

# Check Status Tracker (from sandbox-compatible URL)
curl -s http://status-tracker-app:8000/ | head -n 5

# Update todo status directly via API
curl -X PATCH -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" \
  -d '{"status": "done"}' http://status-tracker-app:8000/todos/{id}
```

## Status Tracker Network Discovery (Heartbeat 2026-02-10)

### Finding: Status Tracker IP Address
- **Location**: `172.18.0.7:8000` (discovered via network scan)
- **Issue**: Hostname `status-tracker` doesn't resolve from main agent container
- **Workaround**: Use IP address directly or configure DNS

### Main Agent Environment Notes
- `python3` works, `python` doesn't (Permission denied)
- `openclaw` CLI not accessible in main agent sandbox
- Container IP: `172.18.0.12` (per `/etc/hosts` and `/proc/net/fib_trie`)
- Network scan command found tracker: `for i in $(seq 1 10); do curl -s --connect-timeout 1 http://172.18.0.$i:8000/docs; done`

### Status Tracker API Access
```bash
# Direct IP access (works)
curl -s http://172.18.0.7:8000/tasks/

# With auth token
TRACKER_URL="http://172.18.0.7:8000" TRACKER_AUTH_TOKEN="..." python3 scripts/tracker_api.py list
```

## Race Condition Fix Deployed (2026-02-10)

### Root Cause
- MCP server used `stateless=True` in StreamableHTTPSessionManager but kept single browser page
- Concurrent requests competed for the same page causing wrong/empty results

### Fix Applied
- Implemented `isolated_context()` async context manager in `manager.py`
- Each request gets fresh browser context with async lock for thread safety
- Pattern: "Single Browser + Context Per Request" - recommended architecture

### Files Modified
- `src/browser/manager.py` - Added `isolated_context()` method

### Verification
- `mcporter call` for "OpenClaw AI assistant" returns correct results ✅
- Container healthy, all tests passing

## Browser Lifecycle Management Feature (Task #41)

### Goal
Implement sub-agent browser isolation with:
- Separate browser instances for sub-agents (not just contexts)
- 30-min auto-cleanup of inactive browsers
- 15-tab limit per browser with LRU eviction
- Session labeling for debugging

### Phase 1: Core Classes (COMPLETED)
**New files created:**

1. **`src/browser/instance.py`** - BrowserInstance class
   - Tracks browser, context, tabs (OrderedDict), last_activity, session_id, is_active
   - 15-tab limit with LRU eviction (`MAX_TABS = 15`)
   - `update_activity()` method for session tracking
   - Thread-safe operations with async locks

2. **`src/browser/subagent_manager.py`** - SubAgentBrowserManager class
   - Dictionary tracking all sub-agent browsers (`self._browsers`)
   - `create_browser(session_id)` - creates new isolated browser instance
   - `get_browser(session_id)` - retrieves existing instance
   - `cleanup_inactive()` background task running every 60s
   - 5-minute idle timeout (`IDLE_TIMEOUT_SECONDS = 300`)
   - Async locks for thread safety
   - Global singleton support via `get_subagent_manager()`

3. **`src/browser/manager.py`** - Updated
   - Imports and initializes SubAgentBrowserManager
   - Cleanup on `stop()`
   - New methods: `get_subagent_browser()`, `close_subagent_browser()`, `list_subagent_sessions()`, `get_subagent_stats()`

### Phase 2: Tool Integration (COMPLETED)
**Files modified:**

1. **`src/tools/brave_search.py`**
   - `brave_search()` accepts optional `session_id` and `manager` parameters
   - `brave_extract()` accepts optional `session_id` and `manager` parameters
   - Both use sub-agent browser when session_id provided, main browser otherwise

2. **`src/server.py`**
   - Added `BROWSER_TIMEOUT_MINUTES` environment variable (defaults to 30)

3. **`src/browser/subagent_manager.py`**
   - `__init__()` accepts `idle_timeout_minutes` parameter

4. **`src/browser/manager.py`**
   - Reads `BROWSER_TIMEOUT_MINUTES` from environment, passes to SubAgentBrowserManager

### Phase 3: Testing (IN PROGRESS)
- Unit tests for BrowserInstance
- Unit tests for SubAgentBrowserManager
- Integration tests for concurrent sessions

### Architecture Decision
- **Main agent**: Persistent browser with isolated contexts per request
- **Sub-agents**: Separate browser instances with 30-min auto-cleanup
- **Tab management**: LRU eviction when 15-tab limit reached
- **Session labeling**: Format `sub-agent-{id}` for easy log filtering

## Opencode Issues (2026-02-10 ~15:30 IST)

### Problem: Free Model Unresponsive
- **Model**: `opencode/kimi-k2.5-free` (Moonshot AI)
- **Symptoms**: Sessions hang indefinitely, no output produced
- **Sessions affected**: `grand-valley` (SIGKILL), `neat-sable` (SIGKILL), `mild-willow`, `dawn-shell`, `cool-harbor`
- **Network**: Verified working (curl to google.com successful)
- **Diagnosis**: Likely provider-side issue or rate limiting on free tier

### Action Needed
- User indicated a model change was previously planned but memory search couldn't locate it
- Need to confirm alternative model: DeepSeek? Gemini? Other?

### Race Condition Fix Plan (Pending Opencode Fix)
- **Approach**: Option 1 - Request-Level Locking
- **Files to modify**:
  1. `src/browser/manager.py` - Add `acquire_for_request()` context manager
  2. `src/tools/brave_search.py` - Wrap full request lifecycle in lock

## OpenClaw Update Scheduled
- **Version**: 2026.2.9 available (current unknown)
- **User confirmation**: Update will be done after 10PM IST today

## AI Summary Extraction Fix (Task #42)

### Problem
- AI summaries from Brave Search were returning empty text
- Debug logs showed `'text': ''` despite element being found
- First words like "Machine learning" were missing

### Root Cause
- Previous code looked for child elements (`.prose, .answer-text, p`) that didn't contain full text
- Brave's AI summary uses `.chatllm-answer-list` class with text directly on parent

### Fix Applied
- Changed to use element's text directly without looking for children
- Primary selector: `.chatllm-answer-list, [class*="chatllm-answer"]`
- Removed overly broad removal selectors

### Files Modified
- `src/tools/brave_search.py` - Updated extraction logic

### Verification
```
Query: "what is python"
Result: "Python is a high-level, general-purpose programming language..." ✅

Query: "what is blockchain technology"  
Result: "Blockchain technology is a decentralized, distributed digital ledger..." ✅
```

### Commits
- `09b4587` - fix: correct AI summary text extraction from Brave Search
- `1418b9f` - fix: enable session_id support in MCP server tools

## Unit Tests Added (2026-02-10)

### AI Summary Tests (`test_ai_summary.py`)
- 15 tests covering AISummary model, SearchResponse model, extraction, edge cases
- Tests: creation, sources, citations, special characters, long text

### Session Routing Tests (`test_session_routing.py`)
- 8 tests covering session_id routing and race condition fixes
- Tests: sub-agent browser isolation, isolated_context thread safety, browser reuse

### Total Test Suite
```
test_ai_summary.py       - 15 tests ✅
test_brave_search.py     - 47 tests ✅
test_browser_lifecycle.py - 7 tests ✅
test_browser_parity.py   - 14 tests ✅
test_captcha.py          - 28 tests ✅
test_server.py           - 4 tests ✅
test_server_unit.py      - 12 tests ✅
test_session_routing.py  - 8 tests ✅
─────────────────────────────────────
TOTAL: 135 tests passing
```

### Commits
- `39243fd` - test: add unit tests for AI Summary extraction feature
- `c46be6c` - test: add session ID routing and race condition tests

## CI Deadlock Fix & Test Restoration (2026-02-10 16:00 IST)

### Problem
- GitHub Actions CI was hanging on "Run tests" step.
- Diagnostic logs showed tests passing up to 85% then stopping.
- Identified deadlock in `SubAgentBrowserManager.stop()`: it tried to acquire `self._lock` while the background `_cleanup_inactive_loop` task held it.

### Fix Applied
- Modified `src/browser/subagent_manager.py`: Cancel the `_cleanup_task` **before** acquiring the lock in `stop()`.
- Re-enabled all tests in `.github/workflows/test.yml` (removed `--ignore` flags) as requested by the user.
- Verified fix locally with `pytest tests/test_browser_lifecycle.py -v` (PASSED).

### Final Status before OpenClaw Update
- Commit `4869f66` pushed to GitHub.
- All 135 tests are active in CI.
- Status Tracker reachable.
- Readiness for OpenClaw update confirmed.
