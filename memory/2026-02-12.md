# 2026-02-12 Notes

## Discord/GLM-5 Model Output Issue

### Problem
GLM-5 on Modal outputs internal narration/status messages in Discord instead of conversational responses:
- Messages like "Responded! Ready for DoCZ's next message."
- "Sent! Ready for..."
- Model narrates its tool calls and actions instead of just responding naturally

### Root Cause (from GitHub Issues)
Found related issues in openclaw/openclaw repo:

1. **Issue #6442**: "Synthetic + Kimi K2.5 leaks 'thinking' blocks into normal assistant output"
   - Model's thinking/reasoning text shown as normal output
   - `{"type": "thinking"}` blocks not properly hidden by OpenClaw

2. **Issue #11922**: "Custom provider via models.providers outputs broken/empty responses"
   - Custom providers return broken responses OR thinking leak
   - Exact same issue we're seeing with Modal GLM-5

3. **Issue #11224**: "Discord channel sessions bypass compaction, causing context overflow"
   - Discord sessions grow unbounded, ignore `contextTokens` limit
   - Eventually causes context overflow errors

### Configurations Tried
- Set `reasoning: true` on GLM-5 model config
- Set `reasoning: false` on GLM-5 model config
- Created isolated `discord-agent` with minimal tools
- Switched to Gemini as primary model
- Added Discord `blockStreamingCoalesce` settings

### Current State
- Primary model: `modal/zai-org/GLM-5-FP8` with `reasoning: true`
- Issue persists - model outputs internal narration in Discord
- Problem appears to be how OpenClaw handles custom provider responses

### Potential Solutions to Try
1. Add model params to disable thinking: `"thinking": {"type":"disabled"}`
2. Use a different provider/model for Discord specifically
3. Wait for upstream fix in OpenClaw for custom provider handling

## Related GitHub Issues
- https://github.com/openclaw/openclaw/issues/6442
- https://github.com/openclaw/openclaw/issues/11922
- https://github.com/openclaw/openclaw/issues/11224
- https://github.com/openclaw/openclaw/issues/8901 (tool event streaming vs verbose mode)
